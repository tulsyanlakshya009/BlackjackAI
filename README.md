# Reinforcement Learningâ€“Based Blackjack AI

This repository contains a complete implementation of a Blackjack AI using tabular Q-learning, dynamic bet-sizing based on card-count probabilities, and a Tkinter GUI for interactive play and real-time AI suggestions.

---

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Repository Structure](#repository-structure)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
  - [Training the AI](#training-the-ai)
  - [Testing the AI](#testing-the-ai)
  - [Running the GUI](#running-the-gui)
- [Algorithms](#algorithms)
  - [MDP Formulation](#mdp-formulation)
  - [Q-Learning Agent](#q-learning-agent)
  - [Bet-Sizing Heuristic](#bet-sizing-heuristic)
  - [Baseline Agent](#baseline-agent)
- [Results](#results)

---

## âœ¨ Features

- **Blackjack Simulator**: Implements standard rules, persistent multi-deck shoe with automatic reshuffle.
- **Q-Learning Agent**: Learns hit/stand policy using Îµ-greedy exploration and dynamic Îµ-decay.
- **Dynamic Bet-Sizing**: Maps card-count probabilities (low/mid/high) to bets (10â€“100) via a damped linear ramp.
- **Baseline Rule-Based Agent**: Simple strategy for benchmarking.
- **Tkinter GUI**: Play interactively, see AI's suggested action and bet in real time.

---

## ğŸ—‚ Repository Structure

```
â”œâ”€â”€ cards.py              # Card & Deck classes for shoe management
â”œâ”€â”€ blackjack.py          # Game logic (deal, hit, score, check_winner)
â”œâ”€â”€ blackjack_ai.py       # Q-learning agent & bet-sizing strategy
â”œâ”€â”€ blackjack_baseline.py # Rule-based baseline agent
â”œâ”€â”€ train_blackjack_ai.py # Training & testing harness (persistent deck)
â”œâ”€â”€ blackjackgui.py       # Tkinter GUI with AI integration
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project overview and usage
```

---

## ğŸ”§ Requirements

- Python 3.8+
- Packages:
  - `numpy`
  - `pillow`
  - `reportlab`

Install via:
```bash
pip install numpy pillow reportlab
```

---

## ğŸš€ Installation

1. Clone this repository:
```bash
git clone https://github.com/tulsyanlakshya009/BlackjackAI.git
cd BlackjackAI
```

---

## ğŸƒ Usage

### Training & Testing the AI

AI is trained over 500,000 hands and tested on 100,000 hands:
```bash
python train_blackjack_ai.py
```

### Running the GUI

Launch the interactive GUI:
```bash
python blackjackgui.py
```
- Use the radio buttons to switch between **AI** and **Baseline**.
- Enter a bet and click **Bet** to start.
- The AI panel displays suggested bet, action, and deck composition percentages.

---

## ğŸ§  Algorithms

### MDP Formulation

- **State**: `(player_total, dealer_up, low_prob, mid_prob, high_prob, bet)`
- **Actions**: `hit` or `stand`
- **Reward**: +1.5Ã—bet on win, 0 on draw, â€“1Ã—bet on loss

### Q-Learning Agent

- Tabular Q-learning with update:
  \(Q(s,a) <- Q(s,a) + Î± [r + Î³ max_{a'} Q(s',a') â€“ Q(s,a)]\)
- Î± = 0.05, Î³ = 0.95
- Îµ-greedy exploration: Îµ decays from 1.0 -> 0.05

### Bet-Sizing Heuristic

1. Compute `low`, `mid`, `high` probabilities from deck
2. Raw advantage: `adv_raw = high â€“ low`
3. Damped: `adv_adj = adv_raw Ã— (1 â€“ mid)` to account for neutral 7â€“9â€™s
4. Normalize to [0,1], then linearly scale to [10,100]
5. Round to nearest multiple of 10

### Baseline Agent

- Fixed bet = 10
- Hit if `player_total <= 16`, stand if >= 17

---

## ğŸ“Š Results

| Metric           | AI Model     | Baseline    |
|------------------|--------------|-------------|
| Total Profit     | â‚¹1,265,025   | â‚¹159,870    |
| Avg Profit/Hand  | 12.65        | 1.60        |
| Win Rate         | 42.13%       | 42.74%      |
| Draw Rate        | 8.59%        | 9.14%       |
| Loss Rate        | 49.28%       | 48.12%      |



